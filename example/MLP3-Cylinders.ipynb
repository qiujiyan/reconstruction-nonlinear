{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../util/')\n",
    "sys.path.append('../datasets/')\n",
    "sys.path.append('../models/')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from scipy.optimize import fmin_cg\n",
    "import scipy.signal\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import *\n",
    "\n",
    "from engine import setup_seed,Namespace,train_vae_one_epoch_test\n",
    "from datasets import build_dataset\n",
    "from models import build_models\n",
    "from monitor import Monitor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "args = Namespace()\n",
    "\n",
    "args.dataset_type ='cylinder2d-p'\n",
    "args.dataset_path =  r'../threeCylinder-grid-256-512-p.npy'\n",
    "args.dataset_mask_path =  r'../.npy'\n",
    "args.test_size = 0.33\n",
    "\n",
    "args.model_type = \"MLP\"\n",
    "args.mod_number = 3\n",
    "args.pod_loss = None\n",
    "\n",
    "args.lr = 1e-4\n",
    "args.step_size = 100\n",
    "args.gamma = 0.1\n",
    "args.epochs=int(1000)\n",
    "\n",
    "args.log_interval = 100\n",
    "args.batch_size = 10\n",
    "args.device='cuda:0'\n",
    "args.word_dir='work_dir/'\n",
    "\n",
    "\n",
    "args.monitorType = \"random\"\n",
    "# args.monitorGridShape = (5,5)\n",
    "args.random_num = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localtime = time.asctime( time.localtime(time.time()) )\n",
    "localtime = localtime.replace(' ','_')\n",
    "localtime = localtime.replace(':','_')\n",
    "print(localtime)\n",
    "log_path = './log/'+localtime\n",
    "\n",
    "os.makedirs(log_path)\n",
    "\n",
    "\n",
    "    \n",
    "with open(log_path+'/arg.txt','w',encoding='utf-8') as f:\n",
    "    f.write(str(vars(args)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_dataset.data - train_dataset.data.mean(axis=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_dataset(dataset_path,dataset_type,test_size,mod_input_shape\n",
    "build_dataset_res= build_dataset(args.dataset_path,args.dataset_type,args.test_size,)\n",
    "train_dataset = build_dataset_res['train_dataset']\n",
    "val_dataset  = build_dataset_res['val_dataset']\n",
    "args.data_shape =  build_dataset_res['data_shape']\n",
    "\n",
    "print(\"val_dataset.shape\",val_dataset.shape)\n",
    "print(\"train_dataset.shape\",train_dataset.shape)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size=args.batch_size)\n",
    "val_loader = DataLoader(val_dataset,batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model = build_models(\n",
    "    args.model_type,\n",
    "    args.data_shape,\n",
    "    args.mod_number,\n",
    "    args.pod_loss\n",
    ")\n",
    "model = build_model['model']\n",
    "args.mod_input_shape=build_model['mod_input_shape']\n",
    "args.mod_output_shape=build_model['mod_output_shape']\n",
    "args.code_shape=build_model['code_shape']\n",
    "\n",
    "\n",
    "with open(log_path+'/model.txt','w',encoding='utf-8') as f:\n",
    "    f.write(str(model))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,mode='min', factor=args.gamma, patience=args.step_size, threshold=0.00001,)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae_one_epoch_test(\n",
    "        model: torch.nn.Module,\n",
    "        train_loader, \n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        device: torch.device, \n",
    "        epoch: int, \n",
    "        mod_input_shape,\n",
    "        mod_output_shape,\n",
    "        log_interval,\n",
    "        ):\n",
    "    \n",
    "    model.train()\n",
    "    for batch_idx, (data) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        B_size = len(data)\n",
    "        B_mod_input_shape = [B_size,]+ list(mod_input_shape)\n",
    "        B_mod_output_shape = [B_size,]+ list(mod_output_shape)\n",
    "        output = model(data.reshape(B_mod_input_shape))\n",
    "        loss_info = model.loss_function(data.reshape(B_mod_output_shape),output)\n",
    "        loss = loss_info['loss']\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# val fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = val_dataset[15]\n",
    "\n",
    "\"\"\"\n",
    "Monitor(self,monitorType ,data_shape,\n",
    "        random_num=None, monitorGridShape=None\n",
    "\"\"\"\n",
    "meansure = Monitor(args.monitorType, args.data_shape,random_num = args.random_num ,mask = None  )\n",
    "mask_map = meansure.grid2D()\n",
    "mask_map = torch.Tensor(mask_map)\n",
    "\n",
    "    \n",
    "def val(targets : List ,m_s  : List ,model,code_shape,output_shape,device):\n",
    "    con_m=[]\n",
    "    for m in m_s:\n",
    "        res = []\n",
    "        for target in targets:\n",
    "            model = model.to(device)\n",
    "            mask_map = m.grid2D()\n",
    "            mask_map = torch.Tensor(mask_map)\n",
    "\n",
    "            target_re = target.reshape(output_shape).to(device)\n",
    "            mask_re   = mask_map.reshape(output_shape).to(device)\n",
    "\n",
    "            f = model.loss_decoder_helper(target_re,mask_re)\n",
    "            fp= model.grad_loss_decoder_helper(target_re,mask_re)\n",
    "\n",
    "            start_code = np.zeros(args.mod_number).astype(np.float32)+0.1\n",
    "            fmin_code =fmin_cg(f,start_code,fprime=fp,disp=False )\n",
    "            B_code_shape = [1,]+list(code_shape)\n",
    "            y_per = model.decode( torch.Tensor(fmin_code.astype(np.float32)).to(device).reshape(B_code_shape))\n",
    "\n",
    "            DS = (target.flatten().detach().cpu()-y_per.flatten().detach().cpu())\n",
    "            D = torch.sqrt((DS**2).sum())\n",
    "            T = torch.sqrt(((target.detach())**2).sum())\n",
    "            L2 = D/T\n",
    "            L2 = L2.cpu().numpy()\n",
    "            \n",
    "            res.append(L2)\n",
    "        res = np.array(res ).mean()\n",
    "        con_m.append(res)\n",
    "    return con_m \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.to(args.device)\n",
    "\n",
    "val_best = np.inf\n",
    "\n",
    "for epoch in range(1, args.epochs+ 1):\n",
    "    model = model.to(args.device)\n",
    "    train_vae_one_epoch_test( \n",
    "        model,  \n",
    "        train_loader, \n",
    "        optimizer, \n",
    "        args.device, \n",
    "        epoch ,\n",
    "        args.mod_input_shape,\n",
    "        args.mod_output_shape,\n",
    "        args.log_interval\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "torch.save(model,log_path+'/MLP3-last.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(target  ,m  ,model,code_shape,output_shape,device):\n",
    "\n",
    "    model = model.to(device)\n",
    "    mask_map,meansure_x,meansure_y = m.grid2D(reqxy=True)\n",
    "    mask_map = torch.Tensor(mask_map)\n",
    "\n",
    "    target_re = (target.float()).reshape(output_shape).to(device)\n",
    "    mask_re   = mask_map.reshape(output_shape).to(device)\n",
    "\n",
    "    f = model.loss_decoder_helper(target_re,mask_re)\n",
    "    fp= model.grad_loss_decoder_helper(target_re,mask_re)\n",
    "\n",
    "    start_code = np.zeros(args.mod_number).astype(np.float32)+0.1\n",
    "    fmin_code =fmin_cg(f,start_code,fprime=fp,disp=False )\n",
    "    B_code_shape = [1,]+list(code_shape)\n",
    "    y_per = model.decode( torch.Tensor(fmin_code.astype(np.float32)).to(device).reshape(B_code_shape))\n",
    "\n",
    "\n",
    "    DS = (target.flatten().detach().cpu()-y_per.flatten().detach().cpu())\n",
    "    D = torch.sqrt((DS**2).sum())\n",
    "    T = torch.sqrt(((target.detach())**2).sum())\n",
    "    L2 = D/T\n",
    "    L2 = L2.cpu().numpy()\n",
    "\n",
    "    y_per = y_per.flatten().detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    return y_per,L2,meansure_x,meansure_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = val_dataset[0]\n",
    "\n",
    "\n",
    "for n in [10,20,30,40,50,60,70,80,90,100,150,200]:\n",
    "    ll=[]\n",
    "    for i in val_dataset[0:10]:\n",
    "        for _ in range(10):\n",
    "            mm = Monitor(args.monitorType, args.data_shape,random_num = n ,mask = np.load(args.dataset_mask_path))\n",
    "            val_res,L2,meansure_x,meansure_y = test(i ,mm,model,args.code_shape,args.mod_output_shape,args.device)\n",
    "            ll.append(L2)\n",
    "            # print(L2)\n",
    "    ll = np.array(ll)\n",
    "    print( n, '\\t',ll.mean(),ll.std())\n",
    "#         print(n,L2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset[10].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = val_dataset[10].to(args.device).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_out =model(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_out = test_data_out.reshape(args.data_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = test_data_out.cpu().detach().numpy().reshape(args.data_shape)\n",
    "gt = test_data.cpu().detach().numpy().reshape(args.data_shape)\n",
    "plt.imshow(out+TM)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gt)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow( out -gt+TM)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
